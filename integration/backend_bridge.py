# rag_data_studio/integration/backend_bridge.py
"""
Integration bridge between RAG Data Studio GUI and existing scraping backend
"""

import sys
import os
from pathlib import Path
from typing import List, Dict, Any
import yaml
import tempfile

# Add existing scraper modules to path
sys.path.append(str(Path(__file__).parent.parent.parent))

from scraper.searcher import search_and_fetch
from scraper.rag_models import EnrichedItem
from utils.logger import setup_logger


class RAGStudioBridge:
    """Bridge between GUI and existing scraping backend"""

    def __init__(self):
        self.logger = setup_logger("RAGStudioBridge", log_file="rag_studio.log")

    def run_scraping_pipeline(self, project_config: Dict[str, Any]) -> List[EnrichedItem]:
        """
        Run scraping pipeline using existing backend with GUI-generated config

        Args:
            project_config: YAML configuration generated by RAG Data Studio

        Returns:
            List of enriched items from scraping pipeline
        """
        try:
            # Create temporary YAML config file
            with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as temp_file:
                yaml.dump(project_config, temp_file, default_flow_style=False, indent=2)
                temp_config_path = temp_file.name

            self.logger.info(f"Running scraping pipeline with config: {temp_config_path}")

            # Use existing search_and_fetch function with config file
            enriched_items = search_and_fetch(
                query_or_config_path=temp_config_path,
                logger=self.logger,
                progress_callback=self._progress_callback
            )

            # Cleanup temp file
            os.unlink(temp_config_path)

            return enriched_items

        except Exception as e:
            self.logger.error(f"Error running scraping pipeline: {e}", exc_info=True)
            return []

    def _progress_callback(self, message: str, percentage: int):
        """Progress callback for GUI updates"""
        self.logger.info(f"Progress: {percentage}% - {message}")
        # In a real implementation, you'd emit a Qt signal here

    def test_selectors_on_url(self, url: str, selectors: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Test scraping rules against a specific URL

        Args:
            url: Target URL to test
            selectors: List of selector configurations

        Returns:
            Test results for each selector
        """
        try:
            import requests
            from bs4 import BeautifulSoup

            self.logger.info(f"Testing {len(selectors)} selectors on {url}")

            # Fetch page
            response = requests.get(url, timeout=10)
            response.raise_for_status()

            soup = BeautifulSoup(response.content, 'html.parser')
            results = {}

            for selector_config in selectors:
                selector = selector_config['selector']
                name = selector_config['name']
                extract_type = selector_config.get('extract_type', 'text')
                attribute_name = selector_config.get('attribute_name')
                is_list = selector_config.get('is_list', False)

                try:
                    elements = soup.select(selector)

                    if not elements:
                        results[name] = {
                            'success': False,
                            'found_count': 0,
                            'sample_values': [],
                            'error': 'No elements found'
                        }
                        continue

                    sample_values = []
                    for elem in elements[:5]:  # Sample first 5
                        if extract_type == 'text':
                            value = elem.get_text(strip=True)
                        elif extract_type == 'attribute' and attribute_name:
                            value = elem.get(attribute_name, '')
                        elif extract_type == 'html':
                            value = str(elem)[:100] + '...' if len(str(elem)) > 100 else str(elem)
                        else:
                            value = elem.get_text(strip=True)

                        if value:
                            sample_values.append(value)

                    results[name] = {
                        'success': True,
                        'found_count': len(elements),
                        'sample_values': sample_values,
                        'selector': selector,
                        'semantic_label': selector_config.get('semantic_label', ''),
                        'rag_importance': selector_config.get('rag_importance', 'medium')
                    }

                except Exception as e:
                    results[name] = {
                        'success': False,
                        'found_count': 0,
                        'sample_values': [],
                        'error': str(e)
                    }

            return results

        except Exception as e:
            self.logger.error(f"Error testing selectors: {e}", exc_info=True)
            return {}

    def validate_rag_output(self, enriched_items: List[EnrichedItem]) -> Dict[str, Any]:
        """
        Validate RAG output for quality and completeness

        Args:
            enriched_items: List of enriched items from scraping

        Returns:
            Validation report
        """
        if not enriched_items:
            return {
                'status': 'error',
                'message': 'No items to validate',
                'statistics': {}
            }

        # Analyze RAG output quality
        stats = {
            'total_items': len(enriched_items),
            'items_with_custom_fields': 0,
            'avg_custom_fields_per_item': 0,
            'semantic_labels_found': set(),
            'rag_importance_distribution': {'low': 0, 'medium': 0, 'high': 0, 'critical': 0},
            'avg_text_length': 0,
            'items_with_entities': 0
        }

        total_custom_fields = 0
        total_text_length = 0

        for item in enriched_items:
            # Custom fields analysis
            if item.custom_fields:
                stats['items_with_custom_fields'] += 1
                total_custom_fields += len(item.custom_fields)

                # Track semantic labels (if stored in metadata)
                for field_name, field_value in item.custom_fields.items():
                    if field_value:  # Only count populated fields
                        # You might store semantic labels in metadata
                        # For now, we'll infer from field names
                        if any(label in field_name.lower() for label in ['name', 'title']):
                            stats['semantic_labels_found'].add('entity_name')
                        elif any(label in field_name.lower() for label in ['rank', 'position']):
                            stats['semantic_labels_found'].add('entity_ranking')
                        elif any(label in field_name.lower() for label in ['score', 'rating']):
                            stats['semantic_labels_found'].add('entity_score')

            # Text content analysis
            if item.primary_text_content:
                total_text_length += len(item.primary_text_content)

            # Entity analysis
            if item.overall_entities:
                stats['items_with_entities'] += 1

        # Calculate averages
        if enriched_items:
            stats['avg_custom_fields_per_item'] = total_custom_fields / len(enriched_items)
            stats['avg_text_length'] = total_text_length / len(enriched_items)

        stats['semantic_labels_found'] = list(stats['semantic_labels_found'])

        # Generate quality assessment
        quality_score = 0
        quality_issues = []

        if stats['avg_custom_fields_per_item'] >= 3:
            quality_score += 25
        else:
            quality_issues.append("Low custom field extraction rate")

        if stats['avg_text_length'] >= 500:
            quality_score += 25
        else:
            quality_issues.append("Short average text content")

        if len(stats['semantic_labels_found']) >= 3:
            quality_score += 25
        else:
            quality_issues.append("Limited semantic label diversity")

        if stats['items_with_entities'] / len(enriched_items) >= 0.7:
            quality_score += 25
        else:
            quality_issues.append("Low entity extraction rate")

        return {
            'status': 'success',
            'quality_score': quality_score,
            'quality_issues': quality_issues,
            'statistics': stats,
            'recommendations': self._generate_recommendations(stats, quality_issues)
        }

    def _generate_recommendations(self, stats: Dict, issues: List[str]) -> List[str]:
        """Generate recommendations for improving RAG output"""
        recommendations = []

        if "Low custom field extraction rate" in issues:
            recommendations.append("Review and refine your CSS selectors for better element targeting")

        if "Short average text content" in issues:
            recommendations.append("Consider targeting main content areas or combining multiple text sections")

        if "Limited semantic label diversity" in issues:
            recommendations.append(
                "Add more semantic labels (entity_name, entity_ranking, etc.) to capture diverse data types")

        if "Low entity extraction rate" in issues:
            recommendations.append(
                "Ensure your scraped content contains enough structured information for entity extraction")

        if not recommendations:
            recommendations.append(
                "Excellent RAG output quality! Consider testing on additional pages to ensure consistency.")

        return recommendations


# rag_data_studio/integration/gui_extensions.py
"""
GUI extensions for better integration with existing backend
"""

from PySide6.QtWidgets import *
from PySide6.QtCore import *
from PySide6.QtGui import *
from typing import List, Dict, Any


class TestResultsDialog(QDialog):
    """Dialog to show selector testing results"""

    def __init__(self, results: Dict[str, Any], parent=None):
        super().__init__(parent)
        self.setWindowTitle("Selector Test Results")
        self.setModal(True)
        self.resize(800, 600)

        layout = QVBoxLayout(self)

        # Results table
        self.results_table = QTableWidget()
        self.results_table.setColumnCount(5)
        self.results_table.setHorizontalHeaderLabels([
            "Rule Name", "Status", "Found Count", "Sample Values", "Semantic Label"
        ])

        # Populate results
        self.results_table.setRowCount(len(results))
        for row, (name, result) in enumerate(results.items()):
            # Name
            self.results_table.setItem(row, 0, QTableWidgetItem(name))

            # Status
            status_item = QTableWidgetItem("✅ Success" if result['success'] else "❌ Failed")
            if result['success']:
                status_item.setBackground(QColor(76, 175, 80, 50))
            else:
                status_item.setBackground(QColor(244, 67, 54, 50))
            self.results_table.setItem(row, 1, status_item)

            # Found count
            self.results_table.setItem(row, 2, QTableWidgetItem(str(result['found_count'])))

            # Sample values
            sample_text = "; ".join(result['sample_values'][:3])
            if len(sample_text) > 100:
                sample_text = sample_text[:97] + "..."
            self.results_table.setItem(row, 3, QTableWidgetItem(sample_text))

            # Semantic label
            semantic_label = result.get('semantic_label', 'N/A')
            self.results_table.setItem(row, 4, QTableWidgetItem(semantic_label))

        self.results_table.resizeColumnsToContents()

        # Close button
        close_btn = QPushButton("Close")
        close_btn.clicked.connect(self.accept)

        layout.addWidget(QLabel("Selector Test Results:"))
        layout.addWidget(self.results_table)
        layout.addWidget(close_btn)


class RAGValidationDialog(QDialog):
    """Dialog to show RAG output validation results"""

    def __init__(self, validation_report: Dict[str, Any], parent=None):
        super().__init__(parent)
        self.setWindowTitle("RAG Output Validation")
        self.setModal(True)
        self.resize(700, 500)

        layout = QVBoxLayout(self)

        # Quality score
        score = validation_report.get('quality_score', 0)
        score_label = QLabel(f"🎯 Quality Score: {score}/100")
        score_label.setFont(QFont("Arial", 16, QFont.Bold))

        if score >= 80:
            score_label.setStyleSheet("color: #4CAF50;")
        elif score >= 60:
            score_label.setStyleSheet("color: #FF9800;")
        else:
            score_label.setStyleSheet("color: #F44336;")

        # Statistics
        stats = validation_report.get('statistics', {})
        stats_group = QGroupBox("📊 Statistics")
        stats_layout = QFormLayout(stats_group)

        stats_layout.addRow("Total Items:", QLabel(str(stats.get('total_items', 0))))
        stats_layout.addRow("Items with Custom Fields:", QLabel(str(stats.get('items_with_custom_fields', 0))))
        stats_layout.addRow("Avg Custom Fields per Item:", QLabel(f"{stats.get('avg_custom_fields_per_item', 0):.1f}"))
        stats_layout.addRow("Avg Text Length:", QLabel(f"{stats.get('avg_text_length', 0):.0f} chars"))
        stats_layout.addRow("Items with Entities:", QLabel(str(stats.get('items_with_entities', 0))))

        # Semantic labels found
        semantic_labels = stats.get('semantic_labels_found', [])
        semantic_text = ", ".join(semantic_labels) if semantic_labels else "None detected"
        stats_layout.addRow("Semantic Labels Found:", QLabel(semantic_text))

        # Issues and recommendations
        issues = validation_report.get('quality_issues', [])
        recommendations = validation_report.get('recommendations', [])

        if issues:
            issues_group = QGroupBox("⚠️ Quality Issues")
            issues_layout = QVBoxLayout(issues_group)
            for issue in issues:
                issues_layout.addWidget(QLabel(f"• {issue}"))

        recommendations_group = QGroupBox("💡 Recommendations")
        recommendations_layout = QVBoxLayout(recommendations_group)
        for rec in recommendations:
            recommendations_layout.addWidget(QLabel(f"• {rec}"))

        # Close button
        close_btn = QPushButton("Close")
        close_btn.clicked.connect(self.accept)

        layout.addWidget(score_label)
        layout.addWidget(stats_group)
        if issues:
            layout.addWidget(issues_group)
        layout.addWidget(recommendations_group)
        layout.addWidget(close_btn)


# Example usage and integration points
if __name__ == "__main__":
    # Example of how to integrate with existing backend
    bridge = RAGStudioBridge()

    # Example project config from GUI
    example_config = {
        "domain_info": {
            "name": "Tennis Data Collection",
            "description": "Professional tennis player statistics",
            "domain": "sports"
        },
        "sources": [{
            "name": "tennis_players",
            "seeds": ["https://www.atptour.com/en/rankings/singles"],
            "source_type": "sports",
            "selectors": {
                "custom_fields": [
                    {
                        "name": "player_name",
                        "selector": ".player-cell .player-name",
                        "extract_type": "text",
                        "semantic_label": "entity_name",
                        "rag_importance": "high",
                        "required": True
                    },
                    {
                        "name": "ranking_position",
                        "selector": ".ranking-cell",
                        "extract_type": "text",
                        "semantic_label": "entity_ranking",
                        "rag_importance": "high",
                        "required": True
                    },
                    {
                        "name": "ranking_points",
                        "selector": ".points-cell",
                        "extract_type": "text",
                        "semantic_label": "entity_score",
                        "rag_importance": "medium",
                        "required": False
                    }
                ]
            },
            "crawl": {
                "depth": 1,
                "delay_seconds": 2.0,
                "respect_robots_txt": True
            },
            "export": {
                "format": "jsonl",
                "output_path": "./data_exports/tennis/atp_rankings.jsonl"
            }
        }]
    }

    # Test selectors
    test_results = bridge.test_selectors_on_url(
        "https://www.atptour.com/en/rankings/singles",
        example_config["sources"][0]["selectors"]["custom_fields"]
    )

    print("Test Results:")
    for name, result in test_results.items():
        print(f"  {name}: {'✅' if result['success'] else '❌'} ({result['found_count']} found)")

    # Run scraping pipeline
    # enriched_items = bridge.run_scraping_pipeline(example_config)

    # Validate RAG output
    # validation_report = bridge.validate_rag_output(enriched_items)
    # print(f"RAG Quality Score: {validation_report['quality_score']}/100")